# بخش دوم: یادگیری نظارتی و رگرسیون خطی

# 📌 وارد کردن کتابخانه‌های مورد نیاز
import numpy as np
import matplotlib.pyplot as plt

# 🧩 معرفی یادگیری نظارتی (Supervised Learning)
'''
در یادگیری نظارتی، مدل از داده‌هایی استفاده می‌کند که ورودی (features) و خروجی (labels) هر دو مشخص هستند.
هدف، یادگیری تابعی است که بتواند خروجی را با کمترین خطا پیش‌بینی کند.
'''

# 🎯 اجزای یادگیری نظارتی
'''
1. فضای ورودی X: ویژگی‌ها یا متغیرهای مستقل (مثلاً متراژ خانه)
2. فضای خروجی Y: متغیر وابسته یا خروجی مورد نظر (مثلاً قیمت خانه)
3. تابع هدف f(x): تابع ناشناخته‌ای که می‌خواهیم تخمین بزنیم
4. تابع فرضیه h(x): تابعی که مدل می‌سازد و تقریب‌زننده‌ی f(x) است
'''

# 📉 رگرسیون خطی چیست؟
'''
رگرسیون نوعی یادگیری نظارتی است که خروجی یک مقدار عددی پیوسته است.
مثال: پیش‌بینی قیمت خانه (مقدار عددی) در مقابل تشخیص اسپم بودن ایمیل (دسته‌بندی)
'''

# 🧠 تعریف تابع فرضیه رگرسیون خطی
'''
تابع رگرسیون خطی به شکل زیر است:
    h_w(x) = w_0 + w_1 * x
که در آن:
- x: ویژگی (مثلاً متراژ خانه)
- w_0: مقدار ثابت (intercept)
- w_1: ضریب وزن (slope)
'''

# 🔢 ایجاد داده‌های نمونه برای نمایش رگرسیون خطی
x = np.array([1, 2, 3, 4, 5])  # ویژگی‌ها (مثلاً متراژ خانه)
y = np.array([2, 4, 5, 4, 5])  # خروجی‌های متناظر (مثلاً قیمت خانه)

# مقداردهی اولیه برای w0 و w1
w0 = 1  # مقدار ثابت
w1 = 0.8  # ضریب وزن

# تعریف تابع فرضیه
def h(x):
    return w0 + w1 * x

# 📊 رسم داده‌ها و خط رگرسیون
plt.scatter(x, y, color='red', label='داده‌های واقعی')
plt.plot(x, h(x), color='blue', label='تابع فرضیه h(x)')
plt.xlabel('x (مثلاً متراژ خانه)')
plt.ylabel('y (مثلاً قیمت خانه)')
plt.title('رگرسیون خطی ساده')
plt.legend()
plt.grid(True)
plt.show()
