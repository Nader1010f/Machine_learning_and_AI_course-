# ğŸ“˜ Ø¨Ø®Ø´ Ú†Ù‡Ø§Ø±Ù…: Ú¯Ø±Ø§Ø¯ÛŒØ§Ù† Ù†Ø²ÙˆÙ„ÛŒ ØªØµØ§Ø¯ÙÛŒ (SGD) Ùˆ Ù…ÛŒÙ†ÛŒâ€ŒØ¨Ú†

Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¨Ø§ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ù…Ø¯Ø±Ù†â€ŒØªØ± Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¢Ø´Ù†Ø§ Ù…ÛŒâ€ŒØ´ÙˆÛŒÙ…:  
Ú¯Ø±Ø§Ø¯ÛŒØ§Ù† Ù†Ø²ÙˆÙ„ÛŒ ØªØµØ§Ø¯ÙÛŒ (Stochastic Gradient Descent) Ùˆ Ù…ÛŒÙ†ÛŒâ€ŒØ¨Ú† (Mini-Batch Gradient Descent)

---

## âš ï¸ Ù…Ø´Ú©Ù„ Ú¯Ø±Ø§Ø¯ÛŒØ§Ù† Ù†Ø²ÙˆÙ„ÛŒ Ú©Ø§Ù…Ù„ (Batch Gradient Descent)

Ø¯Ø± Ø±ÙˆØ´ Ú©Ù„Ø§Ø³ÛŒÚ©ØŒ Ú¯Ø±Ø§Ø¯ÛŒØ§Ù† Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯:

\[
w := w - \eta \cdot \nabla J(w; X_{\text{Ú©Ù„}})
\]

âŒ Ø§ÛŒØ±Ø§Ø¯Ø§Øª:
- Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø³Ù†Ú¯ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯
- Ø³Ø±Ø¹Øª Ù¾Ø§ÛŒÛŒÙ†
- Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø­Ø§ÙØ¸Ù‡ Ø²ÛŒØ§Ø¯

---

## âœ… Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒØ¹â€ŒØªØ±: SGD Ùˆ Mini-Batch

| Ø±ÙˆØ´       | ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡ Ø¯Ø± Ù‡Ø± Ú¯Ø§Ù… | Ù…Ø²Ø§ÛŒØ§ Ùˆ Ù…Ø¹Ø§ÛŒØ¨ |
|-----------|------------------------|----------------|
| **SGD**   | Û± Ù†Ù…ÙˆÙ†Ù‡                 | Ø³Ø±ÛŒØ¹ ÙˆÙ„ÛŒ Ù¾Ø±Ù†ÙˆØ³Ø§Ù† |
| **Mini-Batch** | Ú†Ù†Ø¯ Ù†Ù…ÙˆÙ†Ù‡ (Ù…Ø«Ù„Ø§Ù‹ 16 ÛŒØ§ 64) | Ø³Ø±ÛŒØ¹ØŒ Ù¾Ø§ÛŒØ¯Ø§Ø±ØŒ Ù…Ù†Ø§Ø³Ø¨ GPU |

---

## ğŸ”¢ Ú©Ø¯ Ù¾Ø§ÛŒØªÙˆÙ†: Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø±ÙˆØ´â€ŒÙ‡Ø§

```python
import numpy as np
import matplotlib.pyplot as plt

np.random.seed(0)
x = np.random.rand(100)
y = 2 * x + np.random.randn(100) * 0.1

def compute_mse(w, b, x, y):
    return np.mean((w * x + b - y) ** 2)

def sgd(x, y, epochs=100, lr=0.1):
    w, b = 0.0, 0.0
    losses = []
    for epoch in range(epochs):
        for i in range(len(x)):
            xi = x[i]
            yi = y[i]
            y_pred = w * xi + b
            error = y_pred - yi
            w -= lr * error * xi
            b -= lr * error
        losses.append(compute_mse(w, b, x, y))
    return w, b, losses
```

```python
def minibatch(x, y, batch_size=16, epochs=100, lr=0.1):
    w, b = 0.0, 0.0
    losses = []
    n = len(x)
    for epoch in range(epochs):
        indices = np.random.permutation(n)
        for i in range(0, n, batch_size):
            idx = indices[i:i+batch_size]
            xb = x[idx]
            yb = y[idx]
            y_pred = w * xb + b
            error = y_pred - yb
            w -= lr * np.mean(error * xb)
            b -= lr * np.mean(error)
        losses.append(compute_mse(w, b, x, y))
    return w, b, losses
```

---

## ğŸ“ˆ Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡

```python
w_sgd, b_sgd, loss_sgd = sgd(x, y, epochs=50)
w_mb, b_mb, loss_mb = minibatch(x, y, batch_size=16, epochs=50)

plt.plot(loss_sgd, label='SGD')
plt.plot(loss_mb, label='Mini-Batch')
plt.xlabel('ØªÚ©Ø±Ø§Ø±')
plt.ylabel('MSE')
plt.title('Ù…Ù‚Ø§ÛŒØ³Ù‡ Ú©Ø§Ù‡Ø´ Ø®Ø·Ø§ Ø¯Ø± SGD Ùˆ Mini-Batch')
plt.legend()
plt.grid(True)
plt.show()
```

---

## ğŸ§  Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ

- **SGD** Ø³Ø±ÛŒØ¹ ÙˆÙ„ÛŒ Ù¾Ø±Ù†ÙˆØ³Ø§Ù† Ø§Ø³Øª
- **Mini-Batch** Ú¯Ø²ÛŒÙ†Ù‡Ù” Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø¯Ø± ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† Ù…Ø¯Ø±Ù† Ø§Ø³Øª (Ù…Ø®ØµÙˆØµØ§Ù‹ Ø¨Ø§ GPU)
- Ú¯Ø±Ø§Ø¯ÛŒØ§Ù† Ù†Ø²ÙˆÙ„ÛŒ Ú©Ø§Ù…Ù„ (BGD) ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ù…Ø³Ø§Ø¦Ù„ Ú©ÙˆÚ†Ú© Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³Øª

---